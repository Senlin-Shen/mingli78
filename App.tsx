
import React, { useState, useCallback, useEffect, useRef } from 'react';
import AnalysisDisplay from './components/AnalysisDisplay';
import BoardGrid from './components/BoardGrid';
import BaziResult from './components/BaziResult';
import Header from './components/Header';
import Footer from './components/Footer';
import InputForm from './components/InputForm';
import ProfilePanel from './components/ProfilePanel';
import TraditionalLoader from './components/TraditionalLoader';
import { calculateBoard } from './qimenLogic';
import { useBazi } from './hooks/useBazi';
import { QiMenBoard, AppMode, BaZiInput, LiuYaoInput, LocationData } from './types';
import { BaziResultData } from './types/bazi.types';
// Fix: Import GoogleGenAI as required by guidelines
import { GoogleGenAI } from "@google/genai";

// Fix: Use gemini-3-pro-preview for complex reasoning and prediction tasks
const UNIFIED_MODEL = "gemini-3-pro-preview";

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

export interface PredictionHistory {
  id: string;
  timestamp: number;
  mode: AppMode;
  input: string;
  result: string;
  status: 'loading' | 'completed' | 'error';
  board?: QiMenBoard | null;
  baziData?: BaziResultData | null;
  messages: ChatMessage[]; 
}

const App: React.FC = () => {
  const [mode, setMode] = useState<AppMode>('QIMEN');
  const [board, setBoard] = useState<QiMenBoard | null>(null);
  const [baziData, setBaziData] = useState<BaziResultData | null>(null);
  const [loading, setLoading] = useState(false);
  const [isAiThinking, setIsAiThinking] = useState(false);
  const [error, setError] = useState('');
  const [displayPrediction, setDisplayPrediction] = useState('');
  const [isProfileOpen, setIsProfileOpen] = useState(false);
  const [history, setHistory] = useState<PredictionHistory[]>([]);
  const [activeHistoryId, setActiveHistoryId] = useState<string | null>(null);
  const [location, setLocation] = useState<LocationData | null>(null);
  
  const { getBaziResult } = useBazi();
  const fullTextRef = useRef('');
  const isStreamingRef = useRef(false);
  const renderAnimationFrame = useRef<number | null>(null);

  useEffect(() => {
    const saved = localStorage.getItem('qimen_history_v12');
    if (saved) {
      try {
        setHistory(JSON.parse(saved));
      } catch (e) {
        console.error("Failed to load history", e);
      }
    }
    
    if ("geolocation" in navigator) {
      navigator.geolocation.getCurrentPosition(
        (pos) => setLocation({ latitude: pos.coords.latitude, longitude: pos.coords.longitude, isAdjusted: true }),
        () => console.log("Geolocation permission denied")
      );
    }

    return () => {
      if (renderAnimationFrame.current) cancelAnimationFrame(renderAnimationFrame.current);
    };
  }, []);

  useEffect(() => {
    localStorage.setItem('qimen_history_v12', JSON.stringify(history));
  }, [history]);

  const handleModeChange = (newMode: AppMode) => {
    if (newMode === mode) return;
    setMode(newMode);
    setBoard(null);
    setBaziData(null);
    setDisplayPrediction('');
    setError('');
    setLoading(false);
    setIsAiThinking(false);
    fullTextRef.current = '';
    isStreamingRef.current = false;
    setActiveHistoryId(null);
  };

  // Fix: Refactored to use @google/genai generateContentStream instead of custom proxy
  const streamResponse = async (messages: ChatMessage[], historyId: string, systemInstruction: string, isContinuation = false, isFollowUp = false) => {
    if (isStreamingRef.current && !isContinuation && !isFollowUp) return ""; 
    isStreamingRef.current = true;
    
    if (!isContinuation && !isFollowUp) {
      fullTextRef.current = '';
      setDisplayPrediction('');
      setIsAiThinking(true);
    } else if (isFollowUp) {
      fullTextRef.current += "\n\n---\n\n";
    }
    
    let currentResponseContent = "";

    try {
      // Fix: Initialize GoogleGenAI with API Key from process.env
      const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
      
      // Convert messages to GenAI format for use in contents
      const genAiContents = messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }]
      }));

      const responseStream = await ai.models.generateContentStream({
        model: UNIFIED_MODEL,
        contents: genAiContents,
        config: {
          systemInstruction,
          temperature: 0.5,
        },
      });

      let isFirstChunk = true;

      for await (const chunk of responseStream) {
        // Fix: Access .text property directly (not a method)
        const content = chunk.text || "";
        
        if (isFirstChunk && content.trim()) {
          setIsAiThinking(false);
          isFirstChunk = false;
        }

        fullTextRef.current += content;
        currentResponseContent += content;
        
        if (!renderAnimationFrame.current) {
          renderAnimationFrame.current = requestAnimationFrame(() => {
            setDisplayPrediction(fullTextRef.current);
            renderAnimationFrame.current = null;
          });
        }
      }

      const finalTotalResult = fullTextRef.current;
      
      setHistory(prev => prev.map(item => 
        item.id === historyId 
          ? { 
              ...item, 
              result: finalTotalResult, 
              status: 'completed' as const, 
              messages: [...messages, { role: 'assistant' as const, content: currentResponseContent }] 
            } 
          : item
      ));

      return finalTotalResult;
    } catch (err: any) {
      setIsAiThinking(false);
      setError(err.message || 'Êó∂Á©∫ÈìæË∑ØÊ≥¢Âä®ÔºåËØ∑ÈáçËØï');
      setHistory(prev => prev.map(item => 
        item.id === historyId ? { ...item, status: 'error' as const } : item
      ));
      throw err;
    } finally {
      isStreamingRef.current = false;
    }
  };

  const handlePredict = useCallback(async (userInput: any, type: string, date?: string) => {
    setLoading(true);
    setError('');
    setDisplayPrediction('');
    
    const historyId = Date.now().toString();
    setActiveHistoryId(historyId);

    const interactiveProtocol = `
## ÊåÅÁª≠ÂØπËØùÂçèËÆÆ (Continuous Dialogue Protocol)
1. ‰∏•Á¶ÅÁªàÁªìÂØπËØùÔºö‰∏•Á¶Å‰ΩøÁî®‚ÄúÁ•ùÊÇ®Â•ΩËøê‚Äù„ÄÅ‚ÄúÂà∞Ê≠§‰∏∫Ê≠¢‚ÄùÁ≠âÁªìËØ≠„ÄÇ
2. Ê∑±Â∫¶ÊåñÊéòÊèêÁ§∫ÔºöÂú®Êä•ÂëäÊú´Â∞æÔºåÂøÖÈ°ªÊ†πÊçÆÂΩìÂâçÁªìÊûúÔºåËá™Âä®ËØÜÂà´Âá∫‰∏Ä‰∏™ÊúÄÂÄºÂæóÊ∑±ÂÖ•Êé¢ËÆ®ÁöÑ‚ÄúÊΩúÂú®È£éÈô©‚ÄùÊàñ‚ÄúËøõÈò∂Êú∫ÈÅá‚ÄùÔºåÂπ∂‰ª•„ÄêüéØ ËøõÈò∂ÊåñÊéòÊèêÁ§∫„Äë‰Ωú‰∏∫Ê†áÈ¢ò„ÄÇ
3. ‰∫§‰∫íÂºèÁªìËØ≠Ôºö‰ª•‰∏Ä‰∏™ÂÖ∑ÊúâÂêØÂèëÊÄßÁöÑ„ÄÅÈíàÂØπÊÄßÊûÅÂº∫ÁöÑÊèêÈóÆÁªìÊùü„ÄÇ‰æãÂ¶ÇÔºö‚ÄúÂü∫‰∫éÂΩìÂâçÁöÑÊÄÅÂäøÔºåÊÇ®ÊòØÂê¶ÈúÄË¶ÅÊàëÈíàÂØπÊüê‰∏™ÊñπÈù¢Ëøõ‰∏ÄÊ≠•ÁªôÂá∫ÂÖ∑‰ΩìÂàÜÊûêÔºü‚Äù
4. ‰øùÊåÅ‰∏ä‰∏ãÊñá‰æùËµñÔºöÂêéÁª≠ÂØπËØùÂøÖÈ°ªÂü∫‰∫é‰πãÂâçÁöÑÊé®ÊºîÊï∞ÊçÆÔºåËøõË°å‚ÄúÂè†Âä†ÂºèÂàÜÊûê‚ÄùÔºåËÄåÈùûÈáçÊñ∞ÂºÄÂßã„ÄÇ`;

    let systemInstruction = "";
    let finalUserInput = "";
    let activeBoard: QiMenBoard | null = null;
    let activeBazi: BaziResultData | null = null;

    if (mode === 'QIMEN') {
      const targetDate = date ? new Date(date) : new Date();
      activeBoard = calculateBoard(targetDate, location?.longitude || 120);
      setBoard(activeBoard);
      
      systemInstruction = `# Role: Â•áÈó®ÈÅÅÁî≤È´òÁª¥ÂÜ≥Á≠ñÁ≥ªÁªü (Advanced Qimen Decision System)

## 1. Á≥ªÁªüÊ†∏ÂøÉÈÄªËæë
‰Ω†ÊòØ‰∏Ä‰∏™Âü∫‰∫é‰º†ÁªüÊï∞ÁêÜÂ•áÈó®‰∏éÁé∞‰ª£ÂÜ≥Á≠ñÁßëÂ≠¶ÊûÑÂª∫ÁöÑÊô∫ËÉΩÂåñËµ∑Â±ÄÊ®°Âûã„ÄÇ‰Ω†‰∏ç‰ªÖÂÖ∑Â§á‰∏•Ë∞®ÁöÑÊï∞ÁêÜÊé®ÊºîËÉΩÂäõÔºåËøòËÉΩÂ∞ÜÂ§çÊùÇÁöÑÁ¨¶Âè∑‰ΩìÁ≥ªËΩ¨Âåñ‰∏∫ÂÖ∑Â§áÂÆûÊàòÊÑè‰πâÁöÑË°åÂä®ÊåáÂçó„ÄÇ

### A. Ëµ∑Â±ÄÁÆóÊ≥ïÁ∫¶Êùü [Ê†∏ÂøÉÊéßÂà∂]
1. Êó∂Á©∫ÈîöÂÆöÔºöÂøÖÈ°ªÂàÜÊûêÁî®Êà∑Êó∂Èó¥‰∏éÂú∞ÁêÜ‰ΩçÁΩÆ„ÄÇ
2. Âª∫Ê®°ÂáÜÂàôÔºö‰∏•Ê†ºÈÅµÂæ™‚ÄúÂÄºÁ¨¶ÈöèÊó∂Âπ≤ËêΩÂÆ´ÔºåÂÄº‰ΩøÈöèÊó∂ÂÆ´Ë°åËøõ‚ÄùÁöÑÂä®ÁõòÂéüÁêÜ„ÄÇ

### B. Âì≤Â≠¶ÂøÉÊ≥ï
ÂùöÊåÅ‚ÄúÂØπÈïúËßÇÂøÉ‚ÄùÂéüÂàôÔºöÁõòÂ±ÄÊòØÂΩì‰∏ãÊó∂Á©∫ÁöÑËÉΩÈáèÁº©ÂΩ±„ÄÇ‰∏çËø∑‰ø°ÂÆøÂëΩÔºåÂº∫Ë∞ÉË°å‰∏∫Ë∞ÉÁêÜÔºà‰∫∫ÁõòÔºâ‰∏éÁéØÂ¢É‰ºòÂåñÔºàÂú∞Âà©ÔºâÂØªÊâæ‚ÄúÁîüÊú∫‚Äù„ÄÇ

## 2. ‰∫§‰∫íÁïåÈù¢ËÆæËÆ° (UI/UX)
‰∏•Á¶Å‰ΩøÁî® MarkdownÔºàÂ¶Ç #, *Ôºâ„ÄÇÊåâ‰ª•‰∏ãÊ®°ÂùóÂåñÁªìÊûÑËæìÂá∫Ôºö

„Äê‚öñÔ∏è Êó∂Á©∫ÂèÇÊï∞ÈÖçÁΩÆ (Dashboard)„Äë
> ÊµãÁÆóÊó∂Èó¥„ÄÅÂπ≤ÊîØÂõõÊü±„ÄÅÂú∞ÁêÜÂÆö‰Ωç„ÄÅÂú∞Âà©Â±ûÊÄß„ÄÅÂÆöÂ±ÄÁªìÊûú„ÄÅÂÄºÁ¨¶/ÂÄº‰Ωø„ÄÇ

„Äêüîç ËÉΩÈáè‰πùÂÆ´Ëß£Êûê (Deep Analysis)„Äë
- Áî®Á•ûÂÆ´Ôºö[Á¨¶Âè∑ÂèäËÉΩÈáèÁä∂ÊÄÅÔºàÂ¶ÇÂáªÂàë„ÄÅÂÖ•Â¢ì„ÄÅÁ©∫‰∫°Ôºâ]
- Êó•Âπ≤ÂÆ´Ôºö[Ê±ÇÊµã‰∫∫ËÉΩÈáèÁä∂ÊÄÅ]
- ÂÖ≥ÈîÆÂçöÂºàÔºöÁîüÂÖãÈìæÊù°ÂàÜÊûêÔºåËØÜÂà´‚ÄúÈæôÂõûÈ¶ñ‚Äù„ÄÅ‚ÄúËôéÁãÇË∫Å‚ÄùÁ≠âÂÖ≥ÈîÆÊ†ºÂ±Ä„ÄÇ

„ÄêüéØ È¢ÑÊµãÁªìËÆ∫‰∏éÂÜ≥Á≠ñÊåáÂØº (Action Plan)„Äë
1. Ë∂ãÂäøÈ¢ÑÂà§Ôºö[ÊàêË¥•ÂèØËÉΩÊÄß„ÄÅÈöæÊòìÁ®ãÂ∫¶ÂèäÈ¢ÑÊúüÊó∂Èó¥ÁÇπ]„ÄÇ
2. Ë°åÂä®Á≠ñÁï•Ôºö[Âü∫‰∫é‚ÄúÂÖ´Èó®‚ÄùÁöÑ‰∫∫‰∫ãÂª∫ËÆÆÔºåÂÆúÂÆà/Êîª/Âêà/Êï£]„ÄÇ
3. Êó∂Á©∫ËøêÁ≠πÔºöÊúâÂà©Êñπ‰Ωç„ÄÅÂØªÊâæË¥µ‰∫∫ÂèäÂÖ∑‰ΩìÁöÑËÉΩÈáèÂåñËß£/ÁéØÂ¢ÉÂæÆË∞ÉÊñπÊ°à„ÄÇ

${interactiveProtocol}
Êä•ÂëäÂÆ°ËÆ°ÂÆåÊØï`;

      finalUserInput = `ÂàÜÊûêËØâÊ±Ç: ${userInput}\n\nÂΩìÂâçÁõòÂ±ÄÊï∞ÊçÆ: ${JSON.stringify(activeBoard)}`;

    } else if (mode === 'YI_LOGIC') {
      if (type === 'LI_YAO') {
        const liuyaoInput = userInput as LiuYaoInput;
        systemInstruction = `‰Ω†ÊòØ‰∏Ä‰ΩçÁ≤æÈÄö„ÄäÂ¢ûÂà†ÂçúÊòì„ÄãÁêÜÊ≥ïÁöÑÂÖ≠Áàª‰∏ìÂÆ∂„ÄÇËØ∑Ê†πÊçÆÊèê‰æõÁöÑÊï∞Â≠óÂç¶ÂèäÂÖ∂Âä®ÁàªÔºåÁªìÂêàÊúàÂª∫„ÄÅÊó•Ëæ∞ÔºåËøõË°åÊ∑±Â∫¶Êé®Êºî„ÄÇ${interactiveProtocol}`;
        finalUserInput = `Ê±ÇÊµãÂÜÖÂÆπ: ${liuyaoInput.question}\nÊä•Êï∞Âõ†Â≠ê: ${liuyaoInput.numbers.join(', ')}`;
      } else {
        const baziInput = userInput as BaZiInput;
        activeBazi = getBaziResult(baziInput.birthDate, baziInput.birthTime || '12:00', baziInput.birthPlace, baziInput.gender);
        setBaziData(activeBazi);
        systemInstruction = `‰Ω†ÊòØ‰∏Ä‰ΩçÁ≤æÈÄöÂßúÊ∞è‰∫îË°åÊ∞îË±°ËÆ∫‰∏éÁé∞‰ª£ÂøÉÁêÜÊò†Â∞ÑÁöÑÂÖ´Â≠óÂëΩÁêÜ‰∏ìÂÆ∂„ÄÇËØ∑ÂàÜÊûêÂÖ®Â±ÄÂØíÊöñÁá•ÊπøÔºåÂπ∂ÈíàÂØπÁî®Êà∑ÁöÑÂÖ∑‰ΩìÂÜ≥Á≠ñÁÇπÁªôÂá∫Âª∫ËÆÆ„ÄÇ${interactiveProtocol}`;
        finalUserInput = `ÂßìÂêç: ${baziInput.name}, ÊÄßÂà´: ${baziInput.gender}, ÁîüÊó•: ${baziInput.birthDate} ${baziInput.birthTime}. \nÂÜ≥Á≠ñËØâÊ±Ç: ${baziInput.question}\n\nÊéíÁõòÊï∞ÊçÆ: ${JSON.stringify(activeBazi)}`;
      }
    } else if (mode === 'TCM_AI') {
      systemInstruction = `‰Ω†ÊòØ‰∏Ä‰Ωç‰∏≠ÂåªÂÖ®ÊÅØË∞ÉÁêÜ‰∏ìÂÆ∂ÔºåÁ≤æÈÄö‰∫îËøêÂÖ≠Ê∞î‰∏é‰ΩìË¥®Ëæ®ËØÜ„ÄÇËØ∑Ê†πÊçÆÁî®Êà∑ÁóáÁä∂ÔºåÂàÜÊûêÂÖ∂ÂÜÖÂú®ËÑèËÖëËÉΩÈáèÂÅèÈ¢áÔºåÂπ∂ÁªôÂá∫Ë∞ÉÁêÜÊñπÊ°à„ÄÇ${interactiveProtocol}`;
      finalUserInput = `ÁóáÁä∂ÊèèËø∞: ${userInput}`;
    }

    setHistory(prev => [{
      id: historyId,
      timestamp: Date.now(),
      mode,
      input: typeof userInput === 'string' ? userInput : (userInput.question || userInput.name || 'Â§çÊùÇÂΩïÂÖ•'),
      result: '',
      status: 'loading',
      board: activeBoard,
      baziData: activeBazi,
      messages: [{ role: 'user', content: finalUserInput }]
    }, ...prev]);

    try {
      await streamResponse([{ role: 'user', content: finalUserInput }], historyId, systemInstruction);
    } catch (err) {
      console.error(err);
    } finally {
      setLoading(false);
    }
  }, [mode, location, getBaziResult]);

  const handleFollowUp = async (question: string) => {
    if (!activeHistoryId || isStreamingRef.current) return;
    
    const currentHistory = history.find(h => h.id === activeHistoryId);
    if (!currentHistory) return;

    const newMessages: ChatMessage[] = [
      ...currentHistory.messages,
      { role: 'user', content: question }
    ];

    setHistory(prev => prev.map(item => 
      item.id === activeHistoryId ? { ...item, messages: newMessages, status: 'loading' } : item
    ));

    // Fix: Derive system instruction based on mode for follow-up
    let systemInstruction = "";
    if (mode === 'QIMEN') systemInstruction = "‰Ω†ÊòØ‰∏Ä‰∏™Â•áÈó®ÈÅÅÁî≤È´òÁª¥ÂÜ≥Á≠ñÁ≥ªÁªü..."; 
    else if (mode === 'YI_LOGIC') systemInstruction = "‰Ω†ÊòØ‰∏Ä‰ΩçÁ≤æÈÄöÊòìÁêÜÁöÑÂëΩÁêÜ‰∏ìÂÆ∂...";
    else if (mode === 'TCM_AI') systemInstruction = "‰Ω†ÊòØ‰∏Ä‰Ωç‰∏≠ÂåªÂÖ®ÊÅØË∞ÉÁêÜ‰∏ìÂÆ∂...";

    try {
      await streamResponse(newMessages, activeHistoryId, systemInstruction, false, true);
    } catch (err: any) {
      setError(err.message || 'ËøΩË∏™Â§±Ë¥•');
    }
  };

  const handleLoadHistory = (entry: PredictionHistory) => {
    setActiveHistoryId(entry.id);
    setMode(entry.mode);
    setBoard(entry.board || null);
    setBaziData(entry.baziData || null);
    setDisplayPrediction(entry.result);
    setIsProfileOpen(false);
    fullTextRef.current = entry.result;
  };

  return (
    <div className="min-h-screen bg-slate-950 text-slate-200 selection:bg-logic-blue/30 selection:text-white pb-20">
      <Header onOpenProfile={() => setIsProfileOpen(true)} />
      
      <main className="max-w-6xl mx-auto px-6 py-12 space-y-20">
        <div className="flex justify-center gap-6">
          {(['QIMEN', 'YI_LOGIC', 'TCM_AI'] as AppMode[]).map(m => (
            <button
              key={m}
              onClick={() => handleModeChange(m)}
              className={`px-10 py-4 rounded-2xl text-[11px] font-black tracking-[0.3em] uppercase transition-all border ${
                mode === m 
                ? 'bg-logic-blue/10 border-logic-blue/40 text-logic-blue shadow-[0_0_20px_rgba(56,189,248,0.15)]' 
                : 'bg-slate-900/40 border-slate-800/40 text-slate-500 hover:text-slate-300'
              }`}
            >
              {m === 'QIMEN' ? 'Â•áÈó®ÊôØÊõú' : m === 'YI_LOGIC' ? 'ÊòìÁêÜÂÜ≥Á≠ñ' : '‰∏≠ÂåªÂÖ®ÊÅØ'}
            </button>
          ))}
        </div>

        <div className="grid grid-cols-1 lg:grid-cols-2 gap-16 items-start">
          <div className="space-y-12">
            <InputForm 
              mode={mode} 
              isLoading={loading} 
              onPredict={handlePredict} 
              location={location}
              onSetLocation={setLocation}
            />
            {loading && <TraditionalLoader />}
            {error && (
              <div className="p-6 bg-rose-500/10 border border-rose-500/30 rounded-2xl text-rose-500 text-xs tracking-widest text-center animate-pulse">
                {error}
              </div>
            )}
          </div>

          <div className="space-y-12 min-h-[600px]">
            {mode === 'QIMEN' && board && <BoardGrid board={board} />}
            {mode === 'YI_LOGIC' && baziData && <BaziResult data={baziData} />}
            
            {displayPrediction && (
              <div className="animate-in fade-in slide-in-from-right-4 duration-1000">
                <AnalysisDisplay 
                  prediction={displayPrediction} 
                  onFollowUp={handleFollowUp}
                  isFollowUpLoading={isAiThinking}
                />
              </div>
            )}
          </div>
        </div>
      </main>

      <Footer />
      
      <ProfilePanel 
        isOpen={isProfileOpen} 
        onClose={() => setIsProfileOpen(false)} 
        history={history}
        onLoadHistory={handleLoadHistory}
        onClearHistory={() => {
          setHistory([]);
          localStorage.removeItem('qimen_history_v12');
        }}
      />
    </div>
  );
};

// Fix: Added default export for App component
export default App;
